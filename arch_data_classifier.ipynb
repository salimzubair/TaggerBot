{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "arch-data-classifier.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3KKxfTMqXts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#start tika server. The Tika Server is the Parser\n",
        "#java -jar \"path\\to\\tika-server-1.22.jar\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUIFhCFcqXt-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "1. Reading Texts from Documents and Data Cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST7NJomIqXuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import necessary modules\n",
        "import tika\n",
        "tika.initVM()\n",
        "from tika import parser\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import pytesseract\n",
        "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe\"\n",
        "from pdf2image import convert_from_path, convert_from_bytes\n",
        "from pdf2image.exceptions import (\n",
        "    PDFInfoNotInstalledError,\n",
        "    PDFPageCountError,\n",
        "    PDFSyntaxError)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXnSerZlqXuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define a parameter for tika parsers. This declaration solves the status 422 server error\n",
        "headers = {'X-Tika-PDFextractInlineImages': 'true', \"X-Tika-OCRLanguage\": \"eng\"} "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1JEDKiYqXuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import project data\n",
        "arch_df = pd.read_csv(r\"parsed-arch_data-training-data-2.csv\", encoding = \"ISO-8859-1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTTuliOWqXu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#parse text from scanned files\n",
        "def ocr_pdf(file):\n",
        "    images = convert_from_path(file)\n",
        "    ocr_list = [pytesseract.image_to_string(x) for x in images]\n",
        "    ocr = ''\n",
        "    return ocr.join(ocr_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOF1No5vqXvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Run Tika Parser on Texts\n",
        "def return_parsed(paths):\n",
        "    try:\n",
        "        return parser.from_file(paths, headers=headers)\n",
        "    except:\n",
        "        return 'path error'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrKTiBSKqXvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Extract Text from files\n",
        "def return_texts(parsed, paths):\n",
        "    if 'content' in parsed and parsed['content'] is not None:\n",
        "        return parsed['content'] #extract 'content' from parsed texts\n",
        "    else:\n",
        "        try:\n",
        "            return ocr_pdf(paths) #if no 'content' from tika parser, try OCRing the document\n",
        "        except:\n",
        "            return \"no content\"   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzqZ9o98qXv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Remove trailing and leading whitespace\n",
        "def remove_whitespace(text):\n",
        "    return text.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8sggroeqXv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Parse Files\n",
        "parsed = arch_df.apply(lambda row: return_parsed(row['Path']), axis = 1).compute()\n",
        "arch_df['Parsed'] = parsed "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1-_QyqrqXwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Extract Text\n",
        "texts =  arch_df.apply(lambda row: return_texts(row['Parsed'], row['Path']), axis = 1).compute()\n",
        "arch_df['Texts'] = texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny4n7-v4qXwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Drop rows with no text content\n",
        "no_content = arch_df[arch_df['Texts'] == 'no content'].index\n",
        "arch_df.drop(no_content, inplace=True)\n",
        "isnan = arch_df[arch_df['Arch_Data'].isna() == True].index\n",
        "arch_df.drop(isnan, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFW3soD1qXwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Remove Whitespace from Arch Data Values\n",
        "Arch_Data = arch_df.apply(lambda row: remove_whitespace(row['Arch_Data']), axis = 1)\n",
        "arch_df['Arch_Data'] = Arch_Data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2znsPmY7qXwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save DataFrame as csv file\n",
        "arch_df.to_csv(r\"\\\\esri-shelf\\ESRIENVIROHUB\\TaggerBot\\parsed-arch_data-training-data-2.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-bMwnmvqXwh",
        "colab_type": "code",
        "colab": {},
        "outputId": "119e3333-bd8a-497b-c58d-574a0b5f289f"
      },
      "source": [
        "arch_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(962, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dVPkQt8qXwk",
        "colab_type": "code",
        "colab": {},
        "outputId": "dc689ec2-e8ef-4ed3-c436-ecc5ab047931"
      },
      "source": [
        "#Plot of Document Samples Grouped by Arch Data\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "arch_df.groupby('Arch_Data').Texts.count().plot.bar(ylim=0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGoqMAq0qXwt",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# 2. Model Training and Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1Y-dPBeqXwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create Vectorizer Object\n",
        "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrBFq4OlqXwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create the ML labels by factorizing\n",
        "y, mappings =arch_df.Arch_Data.factorize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT1fKAFtqXw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define X value\n",
        "X = arch_df.Texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHDNHF2DqXw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGwGKk_zqXxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Vectorize X_train and X_test\n",
        "X_train = tfidf.fit_transform(X_train).toarray()\n",
        "X_test = tfidf.transform(X_test).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xb3wlAcqXxG",
        "colab_type": "code",
        "colab": {},
        "outputId": "f5f6188b-2343-402d-fb90-e3aad4d7b27f"
      },
      "source": [
        "# Create the list of alphas: alphas\n",
        "alphas = np.arange(0, 1, .1)\n",
        "\n",
        "# Define train_and_predict()\n",
        "def train_and_predict(alpha):\n",
        "    # Instantiate the classifier: nb_classifier\n",
        "    nb_classifier = MultinomialNB(alpha=alpha)\n",
        "    # Fit to the training data\n",
        "    nb_classifier.fit(X_train, y_train)\n",
        "    # Predict the labels: pred\n",
        "    pred = nb_classifier.predict(X_test)\n",
        "    # Compute accuracy: score\n",
        "    score = metrics.accuracy_score(y_test, pred)\n",
        "    return score\n",
        "\n",
        "# Iterate over the alphas and print the corresponding score\n",
        "for alpha in alphas:\n",
        "    print('Alpha: ', alpha)\n",
        "    print('Score: ', train_and_predict(alpha))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alpha:  0.0\n",
            "Score:  0.9689119170984456\n",
            "\n",
            "Alpha:  0.1\n",
            "Score:  0.9533678756476683\n",
            "\n",
            "Alpha:  0.2\n",
            "Score:  0.9637305699481865\n",
            "\n",
            "Alpha:  0.30000000000000004\n",
            "Score:  0.9637305699481865\n",
            "\n",
            "Alpha:  0.4\n",
            "Score:  0.9533678756476683\n",
            "\n",
            "Alpha:  0.5\n",
            "Score:  0.9430051813471503\n",
            "\n",
            "Alpha:  0.6000000000000001\n",
            "Score:  0.9378238341968912\n",
            "\n",
            "Alpha:  0.7000000000000001\n",
            "Score:  0.927461139896373\n",
            "\n",
            "Alpha:  0.8\n",
            "Score:  0.9119170984455959\n",
            "\n",
            "Alpha:  0.9\n",
            "Score:  0.9015544041450777\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA4tdhoVqXxN",
        "colab_type": "code",
        "colab": {},
        "outputId": "8db38e48-3d3a-4920-de94-543e411102a9"
      },
      "source": [
        "#Build, train and test classifier\n",
        "clf = MultinomialNB(alpha=0.0)\n",
        "clf.fit(X_train, y_train)\n",
        "accuracy = clf.score(X_test, y_test)\n",
        "print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NylML22bqXxR",
        "colab_type": "code",
        "colab": {},
        "outputId": "aa9004c7-466e-41f5-9da6-fb32c096422e"
      },
      "source": [
        "# Predict the labels of the test data: y_pred\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Generate the confusion matrix and classification report\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, target_names = mappings))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[151   0]\n",
            " [  6  36]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           n       0.96      1.00      0.98       151\n",
            "           y       1.00      0.86      0.92        42\n",
            "\n",
            "    accuracy                           0.97       193\n",
            "   macro avg       0.98      0.93      0.95       193\n",
            "weighted avg       0.97      0.97      0.97       193\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIE_ukaZqXxe",
        "colab_type": "code",
        "colab": {},
        "outputId": "4141af1b-888e-48df-cad9-42441653f898"
      },
      "source": [
        "#Chi-squared test to see the unigrams and bigrams most correlated with arch documents\n",
        "features_chi2 = chi2(X_train, y_train)\n",
        "indices = np.argsort(features_chi2[0])\n",
        "feature_names = np.array(tfidf.get_feature_names())[indices]\n",
        "unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
        "bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
        "print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-20:])))\n",
        "print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-20:])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  . Most correlated unigrams:\n",
            ". choquette\n",
            ". heritage\n",
            ". culture\n",
            ". borden\n",
            ". raad\n",
            ". aoa\n",
            ". archaeologist\n",
            ". deposits\n",
            ". flake\n",
            ". precontact\n",
            ". archaeology\n",
            ". artifact\n",
            ". subsurface\n",
            ". artifacts\n",
            ". aia\n",
            ". hca\n",
            ". lithics\n",
            ". lithic\n",
            ". cultural\n",
            ". archaeological\n",
            "  . Most correlated bigrams:\n",
            ". site report07\n",
            ". report file\n",
            ". file archaeology\n",
            ". conservation act\n",
            ". surface lithics\n",
            ". heritage conservation\n",
            ". archaeological materials\n",
            ". archaeological work\n",
            ". recorded archaeological\n",
            ". archaeological remains\n",
            ". archaeological overview\n",
            ". overview assessment\n",
            ". previously recorded\n",
            ". archaeological impact\n",
            ". impact assessment\n",
            ". archaeological potential\n",
            ". archaeological site\n",
            ". cultural material\n",
            ". archaeological sites\n",
            ". archaeology branch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyZ7wp-eqXxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Re-define X using all available data\n",
        "X = tfidf.fit_transform(arch_df.Texts).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYzzvy7GqXxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Re-train classifier using all available data\n",
        "clf = MultinomialNB(alpha=0.0)\n",
        "clf.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nArUJxmAqXxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save trained model\n",
        "model_save = r\"final-arch-model.sav\"\n",
        "pickle.dump(clf, open(model_save, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmTn1y45qXx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Open saved trained model and test\n",
        "loaded_model = pickle.load(open(model_save, 'rb'))\n",
        "accuracy = loaded_model.score(X_test, y_test)\n",
        "print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}